{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4b0ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Prompt engineering is the practice of designing and refining prompts, which are the input queries or instructions given to a language model like GPT-3 or GPT-4, to achieve more accurate, relevant, and helpful outputs. This process involves understanding how the model interprets and generates text based on these prompts, and then iteratively testing and adjusting them to optimize the results.\\n\\nKey components of prompt engineering include:\\n\\n1. **Clarity**: Ensuring the prompt is clear and unambiguous, so the model can interpret it correctly.\\n   \\n2. **Specificity**: Tailoring the prompt to be specific enough to guide the model towards generating the desired type of output.\\n   \\n3. **Context**: Providing sufficient context within the prompt to help the model understand the background or purpose of the request.\\n\\n4. **Structured Input**: Using specific structures or formats to help the model interpret the input more effectively, such as framing questions in a certain way or providing lists or bullet points.\\n\\n5. **Testing and Iteration**: Experimenting with different phrasing and structures, analyzing the outputs, and refining the prompts to improve performance.\\n\\nPrompt engineering is considered an essential skill for leveraging AI language models effectively, especially in applications like chatbots, content generation, coding assistance, or data retrieval. As language models continue to evolve, prompt engineering remains a vital technique for maximizing their utility and effectiveness.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 278, 'prompt_tokens': 12, 'total_tokens': 290, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BvPhjKqwbcSQ1vllbagUZlM1QA7Bt', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--f5de8e20-3240-447b-8e1a-be5f89ea71c1-0' usage_metadata={'input_tokens': 12, 'output_tokens': 278, 'total_tokens': 290, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set environment variables (optional if already loaded by dotenv)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "result = llm.invoke(\"What is Prompt engineering?\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19b8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
